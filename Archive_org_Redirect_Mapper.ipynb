{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Archive.org Redirect Mapper.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXKJ1oF7BCsSMVbIj5BBxs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/searchsolved/search-solved-public-seo/blob/main/Archive_org_Redirect_Mapper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1qK4fgWTsFNU",
        "outputId": "f10b5331-094c-4d2a-c35c-b5ba08232ac7"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install urlextract\n",
        "!pip install polyfuzz\n",
        "!pip install waybackpy\n",
        "!pip install bs4\n",
        "!pip install imgaug==0.2.5\n",
        "!pip install folium==0.2.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Collecting urlextract\n",
            "  Downloading https://files.pythonhosted.org/packages/47/07/6f8e620cb999e6238370313a4595788ba848046794f4390551ae1c137404/urlextract-1.3.0-py3-none-any.whl\n",
            "Collecting uritools\n",
            "  Downloading https://files.pythonhosted.org/packages/5f/fe/44e4381e7fcf89cc32af9f2d83a778e63dbc1e3f80e9625ad00ec0214a0b/uritools-3.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract) (3.0.12)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from urlextract) (1.4.4)\n",
            "Installing collected packages: uritools, urlextract\n",
            "Successfully installed uritools-3.0.2 urlextract-1.3.0\n",
            "Collecting polyfuzz\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/cc/b5d6f358dcabee5c07da46416e3ffe402fb382ecc3d53a417c2958d61bff/polyfuzz-0.3.3-py2.py3-none-any.whl\n",
            "Collecting numpy>=1.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/03/c3526fb4e79a793498829ca570f2f868204ad9a8040afcd72d82a8f121db/numpy-1.21.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7MB 181kB/s \n",
            "\u001b[?25hCollecting rapidfuzz>=0.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/b1/af677055e9d6a38c884c2ed809a820de68ec2627ad2fcb4b3b9706f97131/rapidfuzz-1.4.1-cp37-cp37m-manylinux2010_x86_64.whl (749kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 23.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from polyfuzz) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from polyfuzz) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from polyfuzz) (0.11.1)\n",
            "Requirement already satisfied: joblib>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from polyfuzz) (1.0.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from polyfuzz) (4.41.1)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from polyfuzz) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from polyfuzz) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->polyfuzz) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.3->polyfuzz) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->polyfuzz) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->polyfuzz) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->polyfuzz) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.25.3->polyfuzz) (1.15.0)\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement numpy~=1.19.2, but you'll have numpy 1.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, rapidfuzz, polyfuzz\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.21.0 polyfuzz-0.3.3 rapidfuzz-1.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting waybackpy\n",
            "  Downloading https://files.pythonhosted.org/packages/61/dd/cf026af4e5c630215ed67957728655b92887c37ae9aeb9f2294039acc11d/waybackpy-2.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from waybackpy) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->waybackpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->waybackpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->waybackpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->waybackpy) (3.0.4)\n",
            "Installing collected packages: waybackpy\n",
            "Successfully installed waybackpy-2.4.3\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Collecting imgaug==0.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/60/a06a48d85a7e9062f5870347a3e3e953da30b37928d43b380c949bca458a/imgaug-0.2.5.tar.gz (562kB)\n",
            "\u001b[K     |████████████████████████████████| 563kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.5) (1.15.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.5.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.5) (2.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug==0.2.5) (2.8.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug==0.2.5) (4.4.2)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.5-cp37-none-any.whl size=561439 sha256=28e1fc3001a7bc344aa5a191177df06a01ef8fc4b50bae45ede05e7ac3baf9cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/48/c8/ca3345e8582a078de94243996e148377ef66fdb845557bae0b\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "  Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "Successfully installed imgaug-0.2.5\n",
            "Collecting folium==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/dd/75ced7437bfa7cb9a88b96ee0177953062803c3b4cde411a97d98c35adaf/folium-0.2.1.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-cp37-none-any.whl size=79810 sha256=96990d188df2da66cb0dff2725da9ed5763823e7441fa7891f6945cff829e3cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/09/f0/52d2ef419c2aaf4fb149f92a33e0008bdce7ae816f0dd8f0c5\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lplxcZAkr7XA"
      },
      "source": [
        "from io import StringIO\n",
        "import io\n",
        "from urllib.parse import urlparse\n",
        "from urllib.request import urlopen\n",
        "\n",
        "import pandas as pd\n",
        "import requests as req\n",
        "from bs4 import BeautifulSoup\n",
        "from polyfuzz import PolyFuzz\n",
        "from waybackpy import Cdx\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC1vlKDPsvBC"
      },
      "source": [
        "# set the user agent here\n",
        "user_agent = \"Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "wposqG1Hsy6-",
        "outputId": "e3dc13fc-0ecc-41d6-b7a1-486de275140c"
      },
      "source": [
        "# upload the Screaming Frog crawl File (internal_html.csv)\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-831634b1-7f9e-4f03-9e8a-68da1799692a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-831634b1-7f9e-4f03-9e8a-68da1799692a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-6d53b0d05d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# upload the Screaming Frog crawl File (internal_html.csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     71\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nnL9i2outF31"
      },
      "source": [
        "df_sf = pd.read_csv(io.StringIO(uploaded['internal_html.csv'].decode('utf-8')))\n",
        "print(\"Imported Crawl File ..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1aTjvZxutNpa"
      },
      "source": [
        "# extract the domain name from the crawl\n",
        "extracted_domain = df_sf[\"Address\"]\n",
        "extracted_domain = extracted_domain.iloc[0]\n",
        "url = extracted_domain\n",
        "o = urlparse(url)\n",
        "domain = o.netloc\n",
        "print(\"Detected Domain = \", domain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rkpp5vmFuxoW"
      },
      "source": [
        "# append extracted domain to archive.org txt url\n",
        "archive_url = \"http://web.archive.org/cdx/search/cdx?url=\" + domain + \"*&output=txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xtxLHYyuuycr"
      },
      "source": [
        "# requests - set the session user agent\n",
        "session = req.Session()\n",
        "session.headers.update({'User-Agent': user_agent})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5GRUxD59u9SW"
      },
      "source": [
        "# get the response\n",
        "print(\"\\nDownloading URLs from Archive.org ..\")\n",
        "resp = session.get(archive_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Iz2t5U4ru_AA"
      },
      "source": [
        "# make the df and set the column names\n",
        "df_archive = pd.read_csv(\n",
        "    StringIO(resp.text),\n",
        "    sep=\" \",\n",
        "    names=[\"1\", \"2\", \"Address\", \"Content Type\", \"5\", \"6\", \"7\"],\n",
        "    dtype=str,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vgjxBcD7vBVP"
      },
      "source": [
        "# count the rows\n",
        "count_row = df_archive.shape[0]\n",
        "print(\"\\nDownloaded\", count_row, \"URLs from Archive.org ..\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6b3oQ9cTvDf9"
      },
      "source": [
        "# replace port 80 urls before de-duping\n",
        "df_archive[\"Address\"] = df_archive[\"Address\"].str.replace(\"\\:80\", \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jFwpg5NDvFmJ"
      },
      "source": [
        "# drop duplicate urls\n",
        "df_archive.drop_duplicates(subset=\"Address\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ysc3imVLw1If"
      },
      "source": [
        "# keep only text/http content\n",
        "df_archive = df_archive[df_archive[\"Content Type\"].isin([\"text/html\"])]\n",
        "df_archive[\"Address\"].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "al5nE3B1w2OU"
      },
      "source": [
        "# drop additional non-html pages incorrectly flagged as text/html\n",
        "df_archive = df_archive[\n",
        "    ~df_archive[\"Address\"].str.contains(\n",
        "        \".css|.js|.jpg|.png|.jpeg|.pdf|.JPG|.PNG|.CSS|.JS|.JPEG|.PDF|.ICO|.GIF|.TXT|.ico|ver=|.gif|.txt\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ccNo9BxTw5Ed"
      },
      "source": [
        "# drop marketing tags\n",
        "df_archive = df_archive[~df_archive[\"Address\"].str.contains(\"utm|gclid\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ub_egGPsw_Fz"
      },
      "source": [
        "# drop any additional rows (custom) (Drops brand pages and pagination)\n",
        "df_archive = df_archive[~df_archive[\"Address\"].str.contains(\"/brand|/page|/p=\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NzsBGyIYxA2W"
      },
      "source": [
        "# drop basket related URLs [Should be blocked in robots.txt anyway!]\n",
        "df_archive = df_archive[~df_archive[\"Address\"].str.contains(\"basket|checkout|add|account\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gp6TucmgxEii"
      },
      "source": [
        "# checks if archive.org url is found in the crawl (and drop it if it is)\n",
        "df_archive[\"Match\"] = df_archive[\"Address\"].str.contains('|'.join(df_sf['Address']), case=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_JGtzplNxHs_"
      },
      "source": [
        "# drop matches\n",
        "df_archive = df_archive[~df_archive[\"Match\"].isin([True])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x2E8H-LZxI__"
      },
      "source": [
        "# reindex the columns\n",
        "df_archive = df_archive.reindex(columns=['Address'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u0ha2CcaxK1v"
      },
      "source": [
        "# count the remaining rows\n",
        "remaining_count = df_archive.shape[0]\n",
        "print(\"\\nFiltered to\", remaining_count, \"Qualifying URLs!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M8VG2dxQ5JnH"
      },
      "source": [
        "# # extract valid URLs from list\n",
        "# print(\"Checking Validity of URLs and removing any which are malformed ..\")\n",
        "# extractor = URLExtract()\n",
        "# df_archive['Extracted URL'] = df_archive['Address'].apply(extractor.find_urls)\n",
        "# print(df_archive['Extracted URL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Kh9muFts7ns0"
      },
      "source": [
        "df_archive = df_archive[df_archive[\"Address\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yOK40uQI8N34"
      },
      "source": [
        "# drop port 80 urls\n",
        "df_archive = df_archive[~df_archive[\"Address\"].str.contains(\":80\", na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-S9ie9kexMie"
      },
      "source": [
        "# create list from address column\n",
        "url_list = df_archive['Address']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A4LEU7O7xNqW"
      },
      "source": [
        "# empty list to append to\n",
        "archive_url_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d8rzjd_NxPGM"
      },
      "source": [
        "print(\"\\nGetting URLs from Archive.org to scrape H1s ..\")\n",
        "for url in url_list:\n",
        "  try:\n",
        "      cdx = Cdx(url=url, user_agent=user_agent)\n",
        "      snapshots = cdx.snapshots()\n",
        "\n",
        "      for snapshot in snapshots:\n",
        "          print(snapshot.archive_url)\n",
        "          archive_url_list.append(snapshot.archive_url)\n",
        "  except ValueError:\n",
        "    print(\"Value Error!\")\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nqZpvHkcxQWD"
      },
      "source": [
        "df_temp = pd.DataFrame(archive_url_list, columns=['Recovered Archive URL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Us3szsAexRcU"
      },
      "source": [
        "# extract original url from Recovered Archive URL (for de-duping) and clean the data\n",
        "df_temp[\"Original URL\"] = (df_temp[\"Recovered Archive URL\"].str.split(\"/\").str[5:])\n",
        "df_temp[\"Original URL\"] = df_temp[\"Original URL\"].str.join(\",\")\n",
        "df_temp[\"Original URL\"] = df_temp[\"Original URL\"].str.replace(',', '/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-hoW_4A5xS0w"
      },
      "source": [
        "# drop port 80 urls\n",
        "df_temp = df_temp[~df_temp[\"Original URL\"].str.contains(\":80\", na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rGe1CpB6xUOv"
      },
      "source": [
        "# sort by oldest urls\n",
        "df_temp = df_temp.sort_values(by=\"Recovered Archive URL\", ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mJZlOC-ixVh3"
      },
      "source": [
        "# drop duplicates\n",
        "df_temp.drop_duplicates(subset=['Original URL'], keep=\"first\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xXOJiSE3xXlu"
      },
      "source": [
        "# extract h1s from temp df and make into a list\n",
        "archive_url_list = df_temp['Recovered Archive URL']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ev00ElK5xYh_"
      },
      "source": [
        "print(\"\\nScraping H1s from Archive.org\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rOX3CvmDxbR5"
      },
      "source": [
        "archive_h1_list = []\n",
        "for i in archive_url_list:\n",
        "    try:\n",
        "        html = urlopen(i)\n",
        "        bsh = BeautifulSoup(html.read(), 'html.parser')\n",
        "        print(bsh.h1.text.strip())\n",
        "        archive_h1_list.append(bsh.h1.text.strip())\n",
        "    except AttributeError:\n",
        "        print(\"Got an HTTP 301 response at crawl time\")\n",
        "        archive_h1_list.append(\"Got an HTTP 301 response at crawl time\")\n",
        "    except Exception:\n",
        "        print(\"Error getting URL\")\n",
        "        archive_h1_list.append(\"Error getting URL\")\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i9TSeQP_xdqN"
      },
      "source": [
        "# add list to dataframe column\n",
        "df_temp['H1'] = archive_h1_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vjV4AT5OxibB"
      },
      "source": [
        "# drop redirected urls\n",
        "df_temp = df_temp[~df_temp[\"H1\"].isin([\"Got an HTTP 301 response at crawl time\"])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WhcKj-36xjyq"
      },
      "source": [
        "# merge back into main dataframe\n",
        "df_archive = pd.merge(df_archive, df_temp, left_on=\"Address\", right_on=\"Original URL\", how=\"inner\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "28n4CDq_xlEu"
      },
      "source": [
        "# start poly fuzz\n",
        "df_archive = df_archive[df_archive[\"H1\"].notna()]\n",
        "df_sf = df_sf[df_sf[\"H1-1\"].notna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xbRftnkSxngb"
      },
      "source": [
        "# create lists from dfs\n",
        "df_sf_list = list(df_sf[\"H1-1\"])\n",
        "df_archive_list = list(df_archive[\"H1\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K168CL0RxpHr"
      },
      "source": [
        "# instantiate PolyFuzz model, choose TF-IDF as the similarity measure and match the two lists.\n",
        "model = PolyFuzz(\"TF-IDF\").match(df_archive_list, df_sf_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-QDZhig6xqri"
      },
      "source": [
        "# make the polyfuzz dataframe\n",
        "df_matches = model.get_matches()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FstRDdOlxrob"
      },
      "source": [
        "# make mini dataframe\n",
        "df_sf_mini = df_sf[['H1-1', 'Address']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nimm1iUQxu8c"
      },
      "source": [
        "# merge back in\n",
        "df_archive = pd.merge(df_archive, df_matches, left_on=\"H1\", right_on=\"From\", how=\"inner\")\n",
        "df_archive = pd.merge(df_archive, df_sf_mini, left_on=\"To\", right_on=\"H1-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WFPgjPf0xwqH"
      },
      "source": [
        "# drop duplicate rows\n",
        "df_archive.drop_duplicates(subset=['Address_x'], keep=\"first\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1PAyRzKxx3o"
      },
      "source": [
        "# reindex the columns\n",
        "df_archive = df_archive.reindex(columns=['Address_x', 'Address_y', 'Similarity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3LWSrBzHxzLL"
      },
      "source": [
        "# rename the columns\n",
        "df_archive.rename(columns={'Address_x': 'Recovered Archive URL', \"Address_y\": \"Live URL\"}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "70yBBUmPx0dr"
      },
      "source": [
        "# count the final datframe rows\n",
        "count_row = df_archive.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "njpen6q9x1xt"
      },
      "source": [
        "# check http status of recovered archive.org url\n",
        "# make the list\n",
        "recovered_archive_list = df_archive['Recovered Archive URL']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IjVG-A4_x4HN"
      },
      "source": [
        "print(\"\\nGetting HTTP Status of Source URL..\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-SGL3xe2x5yW"
      },
      "source": [
        "count = 0\n",
        "recovered_status_list = []\n",
        "for url in recovered_archive_list:\n",
        "    try:\n",
        "        url = session.head(i).status_code\n",
        "        count = count + 1\n",
        "        print(\"Crawled\", count, \"of\", count_row, \"URLs\", \"Status:\", url)\n",
        "        recovered_status_list.append(url)\n",
        "    except Exception:\n",
        "        print(\"Exception!\")\n",
        "        recovered_status_list.append(\"Exception Error\")\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o8FJI77MyRtX"
      },
      "source": [
        "df_archive['Status Code'] = recovered_status_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9yf_7sqiyb32"
      },
      "source": [
        "# Change the Datatype for Filtering\n",
        "df_archive['Status Code'] = df_archive['Status Code'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kr_Z70w-ydFe"
      },
      "source": [
        "# Filter Out Non-Valid Stats Codes (E.g. Already Redirected)\n",
        "df_archive = df_archive[~df_archive['Status Code'].str.contains(\"200|301|302|500|503\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uV8-7PkWyeRD"
      },
      "source": [
        "# get the final count\n",
        "final_count = df_archive.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oaGaGuAWyffR"
      },
      "source": [
        "print(\"\\nTotal Valid Opportunity\", final_count, \"URLS\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wQXQ6-HGykKQ"
      },
      "source": [
        "df_archive.to_csv('urls-to-redirect-archive-org.csv')\n",
        "files.download('urls-to-redirect-archive-org.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}